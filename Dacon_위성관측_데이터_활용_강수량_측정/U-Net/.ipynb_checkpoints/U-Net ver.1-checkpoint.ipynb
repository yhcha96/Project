{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L8a2GwqnPlZf"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('drive/My Drive/Colab Notebooks/Project/AIFrenz_Season2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1DQgvZgIPlWU"
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S3nrYREAQHd_"
   },
   "outputs": [],
   "source": [
    "%tensorflow_version 1.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o7eAGM57PlTE"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split , KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-kQjGVDRIEOF"
   },
   "outputs": [],
   "source": [
    "np.random.seed(777)\n",
    "tf.set_random_seed(777)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mltwli5EjyOi"
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XDcNxy68jyjZ"
   },
   "outputs": [],
   "source": [
    "file_path = 'data/dataset'\n",
    "# NUM_TRAIN = 76345\n",
    "# NUM_TEST = 2416"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5pW7i1Kwnxgs"
   },
   "outputs": [],
   "source": [
    "data = np.load(file_path+'/full_train.npy') #train_refined\n",
    "\n",
    "train_image = data[:,:,:,:9]\n",
    "train_label = data[:,:,:,-1]\n",
    "train_label = train_label.reshape([-1,40,40,1])\n",
    "#train_data = np.concatenate((train,label),axis=3)\n",
    "del data\n",
    "#train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q94lC1RrnxZK"
   },
   "outputs": [],
   "source": [
    "# # [이미지 증식 코드]\n",
    "# img_datagen = ImageDataGenerator(rotation_range=90, shear_range=0.5, zoom_range=0.3, horizontal_flip=True, vertical_flip=True, width_shift_range=0.1, height_shift_range=0.1) #zca_epsilon=1e-9, zca_whitening=True\n",
    "# genTrain = img_datagen.flow(train_data, batch_size=100000, shuffle=False)[0]  #batch_size= train_data.shape[0]\n",
    "\n",
    "# train_data = np.concatenate((train_data,genTrain),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FA3zdHmGoYg6"
   },
   "outputs": [],
   "source": [
    "# train_image = train_data[:,:,:,:9]\n",
    "# train_label = train_data[:,:,:,-1]\n",
    "# del train_data #, genTrain\n",
    "# train_image.shape , train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jzn0Zjqej6NB"
   },
   "outputs": [],
   "source": [
    "# train_path = './data/dataset/'      ##### path 수정\n",
    "# image_path = 'train_images.npy'     ##### path 수정\n",
    "# data_path = 'train_data.npy'        ##### path 수정\n",
    "# label_path = 'train_labels.npy'     ##### path 수정\n",
    "\n",
    "# train_image = np.load(train_path+image_path)\n",
    "# #train_data = np.load(train_path+data_path)\n",
    "# train_label = np.load(train_path+label_path)\n",
    "# #train_all = np.concatenate([train_image,train_label],axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iCiJfWWAwflf"
   },
   "outputs": [],
   "source": [
    "# max_val = train_image.max(axis=(0, 1, 2))\n",
    "# min_val = train_image.min(axis=(0, 1, 2))\n",
    "# train_image = (train_image - min_val) / (max_val - min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S0kEj5qxoBdG"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(train_image,train_label, test_size=0.025, random_state=777)\n",
    "#del train_data,train_label\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B2zs4LcFd57_"
   },
   "outputs": [],
   "source": [
    "# 0보다 작은 값이 포함된 데이터 삭제\n",
    "y_train_ = y_train.reshape(-1, y_train.shape[1]*y_train.shape[2])\n",
    "\n",
    "x_train = np.delete(x_train, np.where(y_train_ < 0)[0], axis=0)\n",
    "y_train = np.delete(y_train, np.where(y_train_ < 0)[0], axis=0)\n",
    "y_train = y_train.reshape(-1, x_train.shape[1], x_train.shape[2],1)\n",
    "\n",
    "y_test_ = y_test.reshape(-1, y_test.shape[1]*y_test.shape[2])\n",
    "\n",
    "x_test = np.delete(x_test, np.where(y_test_ < 0)[0], axis=0)\n",
    "y_test = np.delete(y_test, np.where(y_test_ < 0)[0], axis=0)\n",
    "y_test = y_test.reshape(-1, x_test.shape[1], x_test.shape[2],1)\n",
    "\n",
    "#y_train_ = np.delete(y_train_, np.where(y_train_ < 0)[0], axis=0)\n",
    "\n",
    "del y_train_ , y_test_\n",
    "\n",
    "x_train.shape, y_train.shape , x_test.shape , y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F_LpbXB8-0I3"
   },
   "outputs": [],
   "source": [
    "# # # 강수량이 50이상인 데이터만 선택\n",
    "# y_train_ = y_train.reshape(-1, y_train.shape[1]*y_train.shape[2])\n",
    "# x_train = x_train[np.where(np.sum(y_train_,axis=1) > 0)]\n",
    "# y_train = y_train[np.where(np.sum(y_train_,axis=1) > 0)]\n",
    "\n",
    "# y_test_ = y_test.reshape(-1, y_test.shape[1]*y_test.shape[2])\n",
    "# x_test = x_test[np.where(np.sum(y_test_,axis=1) > 0)]\n",
    "# y_test = y_test[np.where(np.sum(y_test_,axis=1) > 0)]\n",
    "\n",
    "# del y_train_ , y_test_\n",
    "# x_train.shape, y_train.shape , x_test.shape , y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Evf6LlqXn9OM"
   },
   "outputs": [],
   "source": [
    "# Load test_images\n",
    "path = './data/dataset/' \n",
    "test_image = np.load(path+'test_images.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n19hbTqZK1rX"
   },
   "outputs": [],
   "source": [
    "# test_image = test_image[:,:,:,:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hBMDfrEXVYRx"
   },
   "source": [
    "# 평가 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ReCqQ_PIXuor"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def mae(y_true, y_pred) :\n",
    "    \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    \n",
    "    y_true = y_true.reshape(1, -1)[0]\n",
    "    \n",
    "    y_pred = y_pred.reshape(1, -1)[0]\n",
    "    \n",
    "    over_threshold = y_true >= 0.1\n",
    "    \n",
    "    return np.mean(np.abs(y_true[over_threshold] - y_pred[over_threshold]))\n",
    "\n",
    "def fscore(y_true, y_pred):\n",
    "    \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    \n",
    "    y_true = y_true.reshape(1, -1)[0]\n",
    "    \n",
    "    y_pred = y_pred.reshape(1, -1)[0]\n",
    "    \n",
    "    remove_NAs = y_true >= 0\n",
    "    \n",
    "    y_true = np.where(y_true[remove_NAs] >= 0.1, 1, 0)\n",
    "    \n",
    "    y_pred = np.where(y_pred[remove_NAs] >= 0.1, 1, 0)\n",
    "    \n",
    "    return(f1_score(y_true, y_pred))\n",
    "\n",
    "def maeOverFscore(y_true, y_pred):\n",
    "    return mae(y_true, y_pred) / (fscore(y_true, y_pred) + 1e-07)\n",
    "\n",
    "def fscore_keras(y_true, y_pred):\n",
    "    score = tf.py_function(func=fscore, inp=[y_true, y_pred], Tout=tf.float32, name='fscore_keras')\n",
    "    return score\n",
    "\n",
    "def maeOverFscore_keras(y_true, y_pred):\n",
    "    score = tf.py_function(func=maeOverFscore, inp=[y_true, y_pred], Tout=tf.float32,  name='custom_mse') \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "87ba7tiNXxeq"
   },
   "outputs": [],
   "source": [
    "def mae_over_fscore(y_true, y_pred):\n",
    "    '''\n",
    "    y_true: sample_submission.csv 형태의 실제 값\n",
    "    y_pred: sample_submission.csv 형태의 예측 값\n",
    "    '''\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_true = y_true.reshape(1, -1)[0]  \n",
    "    \n",
    "    y_pred = np.array(y_pred)\n",
    "    y_pred = y_pred.reshape(1, -1)[0]\n",
    "    \n",
    "    # 실제값이 0.1 이상인 픽셀의 위치 확인\n",
    "    IsGreaterThanEqualTo_PointOne = y_true >= 0.1\n",
    "    \n",
    "    # 실제 값에 결측값이 없는 픽셀의 위치 확인 \n",
    "    IsNotMissing = y_true >= 0\n",
    "    \n",
    "    # mae 계산\n",
    "    mae = np.mean(np.abs(y_true[IsGreaterThanEqualTo_PointOne] - y_pred[IsGreaterThanEqualTo_PointOne]))\n",
    "    \n",
    "    # f1_score 계산 위해, 실제값에 결측값이 없는 픽셀에 대해 1과 0으로 값 변환\n",
    "    y_true = np.where(y_true[IsNotMissing] >= 0.1, 1, 0)\n",
    "    \n",
    "    y_pred = np.where(y_pred[IsNotMissing] >= 0.1, 1, 0)\n",
    "    \n",
    "    # f1_score 계산    \n",
    "    f_score = f1_score(y_true, y_pred) \n",
    "    \n",
    "    # f1_score가 0일 나올 경우를 대비하여 소량의 값 (1e-07) 추가 \n",
    "    return mae / (f_score + 1e-07) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7cj2Tyt_VYth"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4ijTBI5Ln-He"
   },
   "source": [
    "## ver_origin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HiurcY2vn6uS"
   },
   "outputs": [],
   "source": [
    "def conv2d(inputs,filter_size):\n",
    "    conv = Conv2D(filters=filter_size,kernel_size=3,strides=(1,1),padding='same', activation=None,use_bias=True,kernel_initializer='he_normal')(inputs)\n",
    "    conv = BatchNormalization()(conv)\n",
    "    conv = ReLU()(conv)\n",
    "    return conv\n",
    "\n",
    "def maxpool(conv):\n",
    "    conv = MaxPool2D(pool_size=(2,2),strides=None,padding='valid')(conv)\n",
    "    return conv\n",
    "\n",
    "def deconv2d(conv,filter_size):\n",
    "    conv = Conv2DTranspose(filters=filter_size,kernel_size=(3,3),strides=(2,2),padding='same',dilation_rate=(1,1),activation=None,use_bias=True,kernel_initializer='glorot_normal')(conv)\n",
    "\n",
    "    return conv\n",
    "\n",
    "def concat(deconv,conv):\n",
    "    concat = Concatenate(axis=3)([deconv,conv])\n",
    "\n",
    "    return concat\n",
    "\n",
    "def Contracting_Path(inputs,layers=3,base_feature=32):\n",
    "    dw_conv_list = []\n",
    "    feature = base_feature\n",
    "\n",
    "    # Contraction Path\n",
    "    ## Conv Layer 1\n",
    "    conv = conv2d(inputs,base_feature)\n",
    "    conv = conv2d(conv,base_feature)\n",
    "    dw_conv_list.append(conv)\n",
    "\n",
    "    conv = maxpool(conv)\n",
    "\n",
    "    # Conv Layer 2\n",
    "    for layer in range(layers-2):\n",
    "        feature = feature * 2\n",
    "        conv = conv2d(conv,feature)\n",
    "        conv = conv2d(conv,feature)\n",
    "        dw_conv_list.append(conv)\n",
    "\n",
    "        conv = maxpool(conv)\n",
    "\n",
    "    ## Conv Layer 3\n",
    "    feature = feature * 2\n",
    "    conv = conv2d(conv,feature)\n",
    "    conv = conv2d(conv,feature)\n",
    "\n",
    "    return conv , dw_conv_list\n",
    "\n",
    "def Expanding_Path(conv,dw_conv_list):\n",
    "    \n",
    "    while len(dw_conv_list) != 0:\n",
    "        dw_conv = dw_conv_list.pop()\n",
    "        feature = dw_conv.shape[3]\n",
    "\n",
    "        deconv = deconv2d(conv,feature)\n",
    "        conv_cat = concat(deconv,dw_conv)\n",
    "\n",
    "        conv = conv2d(conv_cat , (conv_cat.shape[3]//2))\n",
    "        conv = conv2d(conv , (conv.shape[3]))\n",
    "\n",
    "    return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XiGPhFaBoCkZ"
   },
   "outputs": [],
   "source": [
    "def Unet():\n",
    "    inputs = Input([40,40,9])\n",
    "\n",
    "    conv , dw_conv_list = Contracting_Path(inputs,layers=2,base_feature=64)\n",
    "\n",
    "    conv = Expanding_Path(conv,dw_conv_list)\n",
    "\n",
    "    output = conv2d(conv,1)\n",
    "\n",
    "    model = Model(inputs=inputs,outputs=output)\n",
    "    model.compile(loss=\"mae\", optimizer=\"adam\", metrics=[fscore_keras,maeOverFscore_keras])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sYKuus88oCci"
   },
   "outputs": [],
   "source": [
    "model = Unet()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mtgVjE8b0ex4"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2287231,
     "status": "ok",
     "timestamp": 1590376851638,
     "user": {
      "displayName": "조준형",
      "photoUrl": "",
      "userId": "07026978245339768740"
     },
     "user_tz": -540
    },
    "id": "JZvyxyu3X2hd",
    "outputId": "ff0e2885-3597-49de-ef3c-d460aec74dd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 72203 samples, validate on 1852 samples\n",
      "Epoch 1/50\n",
      "72203/72203 [==============================] - 68s 947us/sample - loss: 0.1129 - fscore_keras: 0.6595 - maeOverFscore_keras: 2.4298 - val_loss: 0.1141 - val_fscore_keras: 0.7001 - val_maeOverFscore_keras: 2.1006\n",
      "Epoch 2/50\n",
      "72203/72203 [==============================] - 68s 937us/sample - loss: 0.1007 - fscore_keras: 0.7090 - maeOverFscore_keras: 2.0261 - val_loss: 0.5618 - val_fscore_keras: 0.1955 - val_maeOverFscore_keras: 10.7047\n",
      "Epoch 3/50\n",
      "72203/72203 [==============================] - 68s 937us/sample - loss: 0.0972 - fscore_keras: 0.7293 - maeOverFscore_keras: 1.9006 - val_loss: 0.1177 - val_fscore_keras: 0.6401 - val_maeOverFscore_keras: 2.4665\n",
      "Epoch 4/50\n",
      "15488/72203 [=====>........................] - ETA: 53s - loss: 0.0990 - fscore_keras: 0.7142 - maeOverFscore_keras: 1.9672"
     ]
    }
   ],
   "source": [
    "ReduceLROnPlateau = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_maeOverFscore_keras',patience=6) # factor=0.05\n",
    "EarlyStop = tf.keras.callbacks.EarlyStopping(monitor='val_maeOverFscore_keras',patience=6,restore_best_weights=True)\n",
    "#LearningRateSchedule = tf.keras.callbacks.LearningRateScheduler(0.01)\n",
    "callbackList = [EarlyStop,ReduceLROnPlateau]\n",
    "\n",
    "model = Unet()\n",
    "hist = model.fit(x_train,y_train,epochs=50,batch_size=128,validation_split=0.025, callbacks = callbackList, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9f2SxDkNodCk"
   },
   "outputs": [],
   "source": [
    "model.save('U-net_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2673,
     "status": "ok",
     "timestamp": 1590472869732,
     "user": {
      "displayName": "조준형",
      "photoUrl": "",
      "userId": "07026978245339768740"
     },
     "user_tz": -540
    },
    "id": "fldOJ5W3QmxU",
    "outputId": "9eafdae4-bb15-444f-acaa-cff2c204f8f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0068890127257877\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(x_test)\n",
    "print(maeOverFscore(y_test,prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aOMuoV9Jxqf7"
   },
   "source": [
    "# Convolution Layer 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0VosQCMHM_ow"
   },
   "outputs": [],
   "source": [
    "num_layer = len(model.layers)\n",
    "test_idx = np.random.randint(2416)\n",
    "show_conv_layer(test_image,test_idx,num_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AF4pudJKDGOZ"
   },
   "source": [
    "## 각 layer의 feature map 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ptj7bKeh8RhO"
   },
   "outputs": [],
   "source": [
    "num_layer = len(model.layers)\n",
    "print('# of Layers:',num_layer)\n",
    "for layer in model.layers:\n",
    "    print(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AYc7cXP9HIOw"
   },
   "outputs": [],
   "source": [
    "def show_conv_layer(test_data,test_idx,num_layer):\n",
    "    img = test_data[test_idx,:,:,:9]\n",
    "    img_tensor = np.expand_dims(img,axis=0)\n",
    "\n",
    "    # 입력 텐서와 출력 텐서의 리스트로 모델 객체 만들기\n",
    "    layer_outputs = [layer.output for layer in model.layers[:num_layer]][1:]\n",
    "    activation_model = Model(inputs=model.input, outputs=layer_outputs)\n",
    "\n",
    "    # 예측 모드로 모델 실행\n",
    "    activations = activation_model.predict(img_tensor)\n",
    "\n",
    "    layer_names = []\n",
    "    for layer in model.layers[:num_layer]:\n",
    "        layer_names.append(layer.name)\n",
    "\n",
    "    images_per_row = 16\n",
    "\n",
    "    for layer_name , layer_activation in zip(layer_names,activations):\n",
    "        n_features = layer_activation.shape[-1]\n",
    "        size = layer_activation.shape[1]\n",
    "        n_cols = n_features // images_per_row\n",
    "        display_grid = np.zeros((size*n_cols,images_per_row*size))\n",
    "\n",
    "        for col in range(n_cols):\n",
    "            for row in range(images_per_row):\n",
    "                channel_image = layer_activation[0,:,:,col*images_per_row + row]\n",
    "                channel_image -= channel_image.mean()\n",
    "                channel_image /= channel_image.std()\n",
    "                channel_image *= 64\n",
    "                channel_image += 128\n",
    "                channel_image = np.clip(channel_image,0,255).astype('uint8')\n",
    "                display_grid[col*size:(col+1)*size,row*size:(row+1)*size] = channel_image\n",
    "\n",
    "        scale = 1. / size\n",
    "        plt.figure(figsize=(scale*display_grid.shape[1],scale*display_grid.shape[0]))\n",
    "        plt.title(layer_name)\n",
    "        plt.grid(False)\n",
    "        plt.imshow(display_grid,aspect='auto',cmap='viridis')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 684,
     "status": "ok",
     "timestamp": 1590482752403,
     "user": {
      "displayName": "조준형",
      "photoUrl": "",
      "userId": "07026978245339768740"
     },
     "user_tz": -540
    },
    "id": "38-a89yfZKaj",
    "outputId": "71ebe69c-79b8-4ca1-c6a6-f94aac1f76cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 40, 40, 9)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 개별 이미지 전처리\n",
    "img = test_image[10,:,:,:9]\n",
    "img_tensor = np.expand_dims(img,axis=0)\n",
    "print(img_tensor.shape)\n",
    "plt.matshow(img_tensor[0,:,:,5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bo5DlGk9YWNQ"
   },
   "outputs": [],
   "source": [
    "# 입력 텐서와 출력 텐서의 리스트로 모델 객체 만들기\n",
    "layer_outputs = [layer.output for layer in model.layers[:15]][1:]\n",
    "activation_model = Model(inputs=model.input, outputs=layer_outputs)\n",
    "\n",
    "# 예측 모드로 모델 실행\n",
    "activations = activation_model.predict(img_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HlOA7e0rZa7R"
   },
   "outputs": [],
   "source": [
    "# 첫번째 합성곱층의 활성값\n",
    "first_layer_activation = activations[0]\n",
    "print(first_layer_activation.shape)\n",
    "# 20번째 채널 시각화\n",
    "plt.matshow(first_layer_activation[0,:,:,1],cmap='viridis')\n",
    "# 16번째 채널 시각화\n",
    "plt.matshow(first_layer_activation[0,:,:,2],cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SN513gjeZa4o"
   },
   "outputs": [],
   "source": [
    "# 중간층의 모든 활성화 채널 시각화\n",
    "layer_names = []\n",
    "for layer in model.layers[:39]:\n",
    "    layer_names.append(layer.name)\n",
    "\n",
    "images_per_row = 16\n",
    "\n",
    "for layer_name , layer_activation in zip(layer_names,activations):\n",
    "    n_features = layer_activation.shape[-1]\n",
    "    size = layer_activation.shape[1]\n",
    "    print(size)\n",
    "    n_cols = n_features // images_per_row\n",
    "    display_grid = np.zeros((size*n_cols,images_per_row*size))\n",
    "\n",
    "    for col in range(n_cols):\n",
    "        for row in range(images_per_row):\n",
    "            channel_image = layer_activation[0,:,:,col*images_per_row + row]\n",
    "            channel_image -= channel_image.mean()\n",
    "            channel_image /= channel_image.std()\n",
    "            channel_image *= 64\n",
    "            channel_image += 128\n",
    "            channel_image = np.clip(channel_image,0,255).astype('uint8')\n",
    "            display_grid[col*size:(col+1)*size,row*size:(row+1)*size] = channel_image\n",
    "\n",
    "    scale = 1. / size\n",
    "    print(scale)\n",
    "    plt.figure(figsize=(scale*display_grid.shape[1],scale*display_grid.shape[0]))\n",
    "    plt.title(layer_name)\n",
    "    plt.grid(False)\n",
    "    plt.imshow(display_grid,aspect='auto',cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vZsfqmYw0sk8"
   },
   "source": [
    "## 필터 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nWBihoeNZa1j"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "# 필터 시각화를 위한 손실 함수 정의\n",
    "layer_name = 'conv2d_21'\n",
    "filter_index = 0\n",
    "\n",
    "layer_output = model.get_layer(layer_name).output\n",
    "loss = K.mean(layer_output[:,:,:,filter_index])\n",
    "\n",
    "# 입력에 대한 손실의 그래디언트 구하기\n",
    "gradient = K.gradient(loss,model.input)[0]\n",
    "gradient /= (K.sqrt(K.mean(K.square(gradient))) + 1e-5)\n",
    "\n",
    "# 입력값에 대한 넘파이 출력값 추출\n",
    "iterate = K.function([model.input],[loss,gradient])\n",
    "\n",
    "loss_value , gradient_value = iterate([np.zeros((1,40,40,9))])\n",
    "\n",
    "# 확률적 경사상승법을 사용한 손실 최대화\n",
    "input_img_data = np.random.random((1,40,40,9))*20 + 128.\n",
    "step = 1.\n",
    "for i in ragne(40):\n",
    "    loss_value , gradient_value = iterate([input_img_data])\n",
    "\n",
    "    input_img_data += gradient_value * step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gT58BlU30woG"
   },
   "outputs": [],
   "source": [
    "# 텐서를 이미지로 형태로 변환하는 함수\n",
    "def deprocess_image(x):\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + 1e-5)\n",
    "    x *= 0.1\n",
    "\n",
    "    x += 0.5\n",
    "    x = np.clip(x,0,1)\n",
    "\n",
    "    x *= 255\n",
    "    x = np.clip(x,0,255).astype('uint8')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J5Vv2r8A0wlf"
   },
   "outputs": [],
   "source": [
    "# 필터 시각화 이미지를 만드는 함수\n",
    "def generate_pattern(layer_name,filter_index,size=150):\n",
    "    layer_output = model.get_layer(layer_name).output\n",
    "    loss = K.mean(layer_output[:,:,:,filter_index])\n",
    "\n",
    "    gradient = K.gradient(loss,model.input)[0]\n",
    "    gradient /= (K.sqrt(K.mean(K.square(gradient))) + 1e-5)\n",
    "\n",
    "    iterate = K.function([model.input],[loss,gradient])\n",
    "\n",
    "    input_img_data = np.random.random((1,size,size,3)) * 20 + 128. # 잡음 섞인 gray scale로 시작\n",
    "\n",
    "    step = 1.\n",
    "    for i in ragne(40):\n",
    "        loss_value , gradient_value = iterate([input_img_data])\n",
    "        input_img_data += gradient_value * step\n",
    "\n",
    "    img = input_img_data[0]\n",
    "    return deprocess_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r1FN1jSJ0wbX"
   },
   "outputs": [],
   "source": [
    "# 층에 있는 각 필터에 반응하는 패턴 생성\n",
    "layer_name = 'block1_conv1'\n",
    "size = 64\n",
    "margin = 5\n",
    "\n",
    "results = np.zeros((8*szie + 7*margin, 8*size + 7*margin, 3), dtype='uint8')\n",
    "\n",
    "for i in range(8):\n",
    "    for j in range(8):\n",
    "        filter_img = generate_pattern(layer_name, i + (j*8),size=size)\n",
    "        horizontal_start = i * size + i * margin\n",
    "        horizontal_end = horizontal_start + size\n",
    "        vertical_start = j * size + j*margin\n",
    "        vertical_end = vertical_start + size\n",
    "\n",
    "        results[horizontal_start:horizontal_end,vertical_start,vertical_end,:] = filter_img\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hn0Scgwz4eNb"
   },
   "source": [
    "## 클래스 활성화 히트맵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x5pCcHAd0wYQ"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "# 모델에 입력하기 위한 전처리\n",
    "img_path = 'data'\n",
    "\n",
    "img = image.load_img(img_path,target_size=(224,224))\n",
    "\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x,axis=0)\n",
    "x = preprocess_input(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cT2pGiTq5LcF"
   },
   "outputs": [],
   "source": [
    "pred = model.predict(x)\n",
    "print('prediced:',decode_predictions(pred,top=3)[0])\n",
    "np.argmax(pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WsqLG5NY5LZF"
   },
   "outputs": [],
   "source": [
    "# Grad_CAM 알고리즘 \n",
    "africa_elephant_output = model.output[:,386]\n",
    "\n",
    "last_conv_layer = model.get_layer('block5_conv3') # 마지막 합성곱층의 특성 맵\n",
    "gradient = K.gradients(africa_elephant_output,last_conv_layer)[0] # 마지막 특성 맵 출력에 대한 코끼리클래스의 그래디언트\n",
    "pooled_gradient = K.mean(gradient,axis=(0,1,2)) # 특성 맵 채널별 그래디언트 평균이 담긴 (512,) 크기의 벡터\n",
    "\n",
    "iterate = K.function([model.input],[pooled_gradient,last_conv_layer.output[0]])\n",
    "\n",
    "pooled_gradient_value , conv_layer_output_value = iterate([x])\n",
    "\n",
    "for i in rage(512):\n",
    "    conv_layer_output_value[:,:,i] *= pooled_gradient_value[i]\n",
    "\n",
    "heatmap = np.mean(conv_layer_output_value,axis=1)\n",
    "\n",
    "heatmap = np.maximum(heatmap,0)\n",
    "heatmap /= np.max(heatmap)\n",
    "plt.matshow(heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YYdG0LRL5LWw"
   },
   "outputs": [],
   "source": [
    "# 원본 이미지에 히트맵 덧붙이기\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread(img_path)\n",
    "\n",
    "heatmap = cv2.resize(heatmap,(img.shape[1],img.shape[0]))\n",
    "\n",
    "heatmap = np.uint8(255*heatmap)\n",
    "\n",
    "heatmap = cv2.applyColorMap(heatmap,cv2.COLORMAP_JET)\n",
    "\n",
    "superimposed_img = heatmap * 0.4 + img\n",
    "\n",
    "cv2.imwrite('저장경로',superimposed_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7393,
     "status": "ok",
     "timestamp": 1590383613523,
     "user": {
      "displayName": "조준형",
      "photoUrl": "",
      "userId": "07026978245339768740"
     },
     "user_tz": -540
    },
    "id": "7kYZqAECke-T",
    "outputId": "4a74dd4c-34ae-4242-ffeb-583508fe0ccc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9459180652631742"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test = model.predict(x_test)\n",
    "mae_over_fscore(y_test,pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U3NWZv5UuhUp"
   },
   "outputs": [],
   "source": [
    "row, col, pixel = x_test.shape[1:]\n",
    "\n",
    "# 4D input.\n",
    "x = Input(shape=(row, col, pixel))\n",
    "\n",
    "# Encodes a row of pixels using TimeDistributed Wrapper.\n",
    "encoded_rows = TimeDistributed(LSTM(40))(x)\n",
    "\n",
    "# Encodes columns of encoded rows.\n",
    "encoded_columns = LSTM(40)(encoded_rows)\n",
    "\n",
    "# Final predictions and model.\n",
    "prediction = Dense(1, activation='relu')(encoded_columns)\n",
    "model = Model(x, prediction)\n",
    "model.compile(loss='mae',optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s7HGEnDCkTaf"
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/lucasb-eyer/pydensecrf.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FPGZhs1UkTXp"
   },
   "outputs": [],
   "source": [
    "model = fcn_8()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2xxJwtJXS5on"
   },
   "outputs": [],
   "source": [
    "!pip install pystruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A0TJPSYLP-_n"
   },
   "outputs": [],
   "source": [
    "from pystruct.models import LatentGridCRF\n",
    "from pystruct.learners import LatentSSVM, OneSlackSSVM\n",
    "\n",
    "crf = LatentGridCRF(n_states_per_label=2)\n",
    "base_ssvm = OneSlackSSVM(model=crf, C=10., n_jobs=-1, inference_cache=20,tol=.1)\n",
    "clf = LatentSSVM(base_ssvm=base_ssvm)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "print(\"Score training set: %f\" % clf.score(X_train, Y_train))\n",
    "print(\"Score test set: %f\" % clf.score(X_test, Y_test))\n",
    "\n",
    "#Y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_hyiBSkZfQb5"
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/keras-team/keras-contrib.git\n",
    "# !pip install git+https://www.github.com/keras-team/keras-contrib.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dJWl2iZ9b5yC"
   },
   "outputs": [],
   "source": [
    "def train_model(x_data, y_data, k, s):\n",
    "    models = []\n",
    "    k_fold = KFold(n_splits=k, shuffle=True, random_state=777)\n",
    "    \n",
    "    model_number = 0\n",
    "    for train_idx, val_idx in k_fold.split(x_data):\n",
    "        if model_number != s:\n",
    "            x_train, y_train = x_data[train_idx], y_data[train_idx]\n",
    "            x_val, y_val = x_data[val_idx], y_data[val_idx]\n",
    "\n",
    "            model = Unet()\n",
    "\n",
    "            ReduceLROnPlateau = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',patience=3) # factor=0.05\n",
    "            EarlyStop = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=3,restore_best_weights=True)\n",
    "            #ModelCkpt = tf.keras.callbacks.ModelCheckpoint(filepath='ckpt/Unet_' + str(model_number)+'.h5',monitor='val_loss',save_best_only=True)\n",
    "            callbackList = [EarlyStop,ReduceLROnPlateau]\n",
    "\n",
    "            print('val:',model_number)\n",
    "            model.fit(x_train, y_train, epochs=50, batch_size=512, validation_data=(x_val, y_val), callbacks=callbackList)\n",
    "            models.append(model)\n",
    "        \n",
    "            model_number += 1\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lt6ASeW1d2_2"
   },
   "outputs": [],
   "source": [
    "n = 0\n",
    "k = 5\n",
    "preds = []\n",
    "\n",
    "# for i in range(k):\n",
    "#     print('val:',i)\n",
    "#     models = train_model(x_train, y_train, k=k, s=4)\n",
    "\n",
    "models = train_model(x_train, y_train, k=k, s=4)\n",
    "\n",
    "for model in models:\n",
    "    model.save('ckpt/Unet_val_'+str(n)+'.h5')\n",
    "    n += 1\n",
    "\n",
    "for model in models:\n",
    "    preds.append(model.predict(x_test))\n",
    "    print(mae_over_fscore(y_test, preds[-1]))\n",
    "\n",
    "preds = np.array(preds)\n",
    "pred = np.array(preds).mean(axis=0)\n",
    "print(mae_over_fscore(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MOM5YZYitM3v"
   },
   "outputs": [],
   "source": [
    "# model.evaluate(x_test,y_test,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4239,
     "status": "ok",
     "timestamp": 1590026076136,
     "user": {
      "displayName": "조준형",
      "photoUrl": "",
      "userId": "07026978245339768740"
     },
     "user_tz": -540
    },
    "id": "SF4ux51fJPS_",
    "outputId": "5b9fc7f1-36b9-43ac-8354-d39978b53a9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2582678803061162\n",
      "1.2582678803061162\n"
     ]
    }
   ],
   "source": [
    "# val test\n",
    "preds = []\n",
    "for model in models:\n",
    "    preds.append(model.predict(x_test))\n",
    "    print(mae_over_fscore(y_test, preds[-1]))\n",
    "\n",
    "preds = np.array(preds)\n",
    "predictions = preds.mean(axis=0)\n",
    "print(mae_over_fscore(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DA-Tpia68nRZ"
   },
   "outputs": [],
   "source": [
    "# prediction\n",
    "preds = []\n",
    "for model in models:\n",
    "    preds.append(model.predict(test_image))\n",
    "\n",
    "preds = np.array(preds)\n",
    "prediction = np.array(preds).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JDZVa7ou8Hjz"
   },
   "outputs": [],
   "source": [
    "test_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ir0OkWYI71kn"
   },
   "outputs": [],
   "source": [
    "prediction = model.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0r4FrViwuu06"
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('data/sample_submission.csv')\n",
    "submission.iloc[:,1:] = prediction.reshape([-1,1600])\n",
    "submission.to_csv('data/U_Net_ver1_3_20200525.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_lgP6c3nQzqU"
   },
   "outputs": [],
   "source": [
    "model.save('U_Net_200525_ver_1_3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "egKwvZfiG3vL"
   },
   "outputs": [],
   "source": [
    "test_image.shape"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "U-Net ver.1",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
